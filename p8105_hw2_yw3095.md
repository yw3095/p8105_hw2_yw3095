p8105\_hw2\_yw3095
================
Yixuan Wang
September 30, 2018

Problem 1
---------

This problem focuses on NYC Transit data

-   Read and clean the data

``` r
hw2_transit = 
  read_csv("./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv", 
           col_names = TRUE) %>% 
  janitor::clean_names() %>% 
  gather(key = route_number, 
         value = route_name, 
         route1:route11) %>% 
  select(line:station_longitude,
         route_number, 
         route_name, 
         entry, 
         vending, 
         entrance_type, 
         ada) %>%
  filter(!is.na(route_name)) %>% 
  mutate(entry = ifelse(entry == "YES", yes = TRUE, no = FALSE))
```

    ## Parsed with column specification:
    ## cols(
    ##   .default = col_character(),
    ##   `Station Latitude` = col_double(),
    ##   `Station Longitude` = col_double(),
    ##   Route8 = col_integer(),
    ##   Route9 = col_integer(),
    ##   Route10 = col_integer(),
    ##   Route11 = col_integer(),
    ##   ADA = col_logical(),
    ##   `Free Crossover` = col_logical(),
    ##   `Entrance Latitude` = col_double(),
    ##   `Entrance Longitude` = col_double()
    ## )

    ## See spec(...) for full column specifications.

``` r
hw2_transit
```

    ## # A tibble: 4,270 x 10
    ##    line  station_name station_latitude station_longitu~ route_number
    ##    <chr> <chr>                   <dbl>            <dbl> <chr>       
    ##  1 4 Av~ 25th St                  40.7            -74.0 route1      
    ##  2 4 Av~ 25th St                  40.7            -74.0 route1      
    ##  3 4 Av~ 36th St                  40.7            -74.0 route1      
    ##  4 4 Av~ 36th St                  40.7            -74.0 route1      
    ##  5 4 Av~ 36th St                  40.7            -74.0 route1      
    ##  6 4 Av~ 45th St                  40.6            -74.0 route1      
    ##  7 4 Av~ 45th St                  40.6            -74.0 route1      
    ##  8 4 Av~ 45th St                  40.6            -74.0 route1      
    ##  9 4 Av~ 45th St                  40.6            -74.0 route1      
    ## 10 4 Av~ 53rd St                  40.6            -74.0 route1      
    ## # ... with 4,260 more rows, and 5 more variables: route_name <chr>,
    ## #   entry <lgl>, vending <chr>, entrance_type <chr>, ada <lgl>

**steps to clean the data**

describe what happened

**questions**

-   How many distinct stations are there?

    -   There are 465 distinct stations.

-   How many distinct stations are ADA compliant?

    -   There are 84 distinct stations are ADA compliant.

-   What proportion of station entrances / exits without vending allow entrance?

    -   43.43% of station entrances / exits without vending allow entrance.

-   How many distinct stations serve the A train? Of the stations that serve the A train, how many are ADA compliant?

    -   There are 60 distinct stations serve the A train. Of the stations that serve the A train, 17 stations are ADA compliant.

Problem 2
---------

This problem focuses on the Mr. Trash Wheel dataset.

-   Read and clean the data

``` r
hw2_wheel = 
  read_excel("./data/HealthyHarborWaterWheelTotals2017-9-26.xlsx", 
             range = cell_cols(1:14),
             col_names = TRUE) %>% 
  janitor::clean_names() %>% 
  filter(date != 0) %>% 
  mutate(sports_balls = as.integer(round(sports_balls)))
hw2_wheel
```

    ## # A tibble: 215 x 14
    ##    dumpster month  year date                weight_tons volume_cubic_ya~
    ##       <dbl> <chr> <dbl> <dttm>                    <dbl>            <dbl>
    ##  1        1 May    2014 2014-05-16 00:00:00        4.31               18
    ##  2        2 May    2014 2014-05-16 00:00:00        2.74               13
    ##  3        3 May    2014 2014-05-16 00:00:00        3.45               15
    ##  4        4 May    2014 2014-05-17 00:00:00        3.1                15
    ##  5        5 May    2014 2014-05-17 00:00:00        4.06               18
    ##  6        6 May    2014 2014-05-20 00:00:00        2.71               13
    ##  7        7 May    2014 2014-05-21 00:00:00        1.91                8
    ##  8        8 May    2014 2014-05-28 00:00:00        3.7                16
    ##  9        9 June   2014 2014-06-05 00:00:00        2.52               14
    ## 10       10 June   2014 2014-06-11 00:00:00        3.76               18
    ## # ... with 205 more rows, and 8 more variables: plastic_bottles <dbl>,
    ## #   polystyrene <dbl>, cigarette_butts <dbl>, glass_bottles <dbl>,
    ## #   grocery_bags <dbl>, chip_bags <dbl>, sports_balls <int>,
    ## #   homes_powered <dbl>

-   Read and clean precipitation data for 2016

``` r
pre_2016 = 
  read_excel("./data/HealthyHarborWaterWheelTotals2017-9-26.xlsx", 
                      sheet = 4,
                      range = cell_rows(2:14),
                      col_names = TRUE) %>%
  janitor::clean_names() %>% 
  mutate(year = 2016)
pre_2016
```

    ## # A tibble: 12 x 3
    ##    month total  year
    ##    <dbl> <dbl> <dbl>
    ##  1     1  3.23  2016
    ##  2     2  5.32  2016
    ##  3     3  2.24  2016
    ##  4     4  1.78  2016
    ##  5     5  5.19  2016
    ##  6     6  3.2   2016
    ##  7     7  6.09  2016
    ##  8     8  3.96  2016
    ##  9     9  4.53  2016
    ## 10    10  0.62  2016
    ## 11    11  1.47  2016
    ## 12    12  2.32  2016

-   Read and clean precipitation data for 2017

``` r
pre_2017 = 
  read_excel("./data/HealthyHarborWaterWheelTotals2017-9-26.xlsx", 
                      sheet = 3,
                      range = cell_rows(2:10),
                      col_names = TRUE) %>%
  janitor::clean_names() %>% 
  mutate(year = 2017)
```

-   Combine the datasets

``` r
pre_comb = 
  bind_rows(pre_2016, pre_2017) %>%
  mutate(month = month.name[month])
pre_comb
```

    ## # A tibble: 20 x 3
    ##    month     total  year
    ##    <chr>     <dbl> <dbl>
    ##  1 January    3.23  2016
    ##  2 February   5.32  2016
    ##  3 March      2.24  2016
    ##  4 April      1.78  2016
    ##  5 May        5.19  2016
    ##  6 June       3.2   2016
    ##  7 July       6.09  2016
    ##  8 August     3.96  2016
    ##  9 September  4.53  2016
    ## 10 October    0.62  2016
    ## 11 November   1.47  2016
    ## 12 December   2.32  2016
    ## 13 January    2.34  2017
    ## 14 February   1.46  2017
    ## 15 March      3.57  2017
    ## 16 April      3.99  2017
    ## 17 May        5.64  2017
    ## 18 June       1.4   2017
    ## 19 July       7.09  2017
    ## 20 August     4.44  2017

**summary**

There are 215 observations in the Mr. Trash Wheel dataset, and the key variables are ???. There are 20 observations in the combined precipitatin data for 2016 and 2017, and the key variable is ???.

``` r
filter(hw2_wheel, year == 2016, !is.na(sports_balls)) %>% 
  pull(sports_balls) %>% 
  median()
```

    ## [1] 26

The total precipitation in 2017 is 29.93. The median number of sports balls in a dumpster in 2016 is 26.

problem 3
---------

upload the dataset from the p8105.datasets package

``` r
devtools::install_github("p8105/p8105.datasets")
```

    ## Skipping install of 'p8105.datasets' from a github remote, the SHA1 (21f5ad1c) has not changed since last install.
    ##   Use `force = TRUE` to force installation

``` r
library(p8105.datasets)
```

-   Read and clean the data maybe select again to adjust the order!!

``` r
hw2_brfss = brfss_smart2010 %>% 
  janitor::clean_names() %>% 
  filter(topic == "Overall Health") %>% 
  separate(locationdesc, into = c("remove", "location_county"), sep = " - ") %>% 
  rename(location_state = locationabbr) %>%
  select(year, location_state, location_county, response, data_value) %>% 
  spread(key = response, value = data_value) %>%
  janitor::clean_names() %>%
  select(year:location_county, excellent, very_good, good, fair, poor) %>% 
  mutate(above_good = excellent + very_good) 
hw2_brfss
```

    ## # A tibble: 2,125 x 9
    ##     year location_state location_county excellent very_good  good  fair
    ##    <int> <chr>          <chr>               <dbl>     <dbl> <dbl> <dbl>
    ##  1  2002 AK             Anchorage Muni~      27.9      33.7  23.8   8.6
    ##  2  2002 AL             Jefferson Coun~      18.5      30.9  32.7  12.1
    ##  3  2002 AR             Pulaski County       24.1      29.3  29.9  12.5
    ##  4  2002 AZ             Maricopa County      21.6      36.6  26.9  10.3
    ##  5  2002 AZ             Pima County          26.6      30.1  31.9   7.5
    ##  6  2002 CA             Los Angeles Co~      22.7      29.8  28.7  14.3
    ##  7  2002 CO             Adams County         21.2      31.2  29    14.4
    ##  8  2002 CO             Arapahoe County      25.5      35.2  29.3   8  
    ##  9  2002 CO             Denver County        22.2      27.1  36.6  11.1
    ## 10  2002 CO             Jefferson Coun~      23.4      36.6  26.3  11.4
    ## # ... with 2,115 more rows, and 2 more variables: poor <dbl>,
    ## #   above_good <dbl>

**Questions**

``` r
count(hw2_brfss, location_state) %>% 
  arrange(-n) %>% 
  head(1)
```

    ## # A tibble: 1 x 2
    ##   location_state     n
    ##   <chr>          <int>
    ## 1 NJ               146

-   There are 404 unique locations are included in the dataset. There are 51 states in the dataset. Every state is represented. NJ is observed 146 times, which is the most.

-   In 2002, what is the median of the “Excellent” response value?

    -   In 2002, the median of the "Excellent" response value is 23.6.

``` r
filter(hw2_brfss, year == 2002, !is.na(excellent)) %>% 
  pull(excellent) %>% 
  median()
```

    ## [1] 23.6

-   Make a histogram of “Excellent” response values in the year 2002.

``` r
res_2002 = filter(hw2_brfss, year == 2002) %>% 
            ggplot(aes(x = excellent)) + 
            geom_histogram() + 
            labs(
    title = "“Excellent” response distribution in the year 2002",
    x = "excellent reponse proportion",
    y = "count") + 
            scale_x_continuous(breaks = c(20, 30, 40), 
                     labels = c("20%", "30", "40")) 
res_2002
```

    ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.

    ## Warning: Removed 2 rows containing non-finite values (stat_bin).

<img src="p8105_hw2_yw3095_files/figure-markdown_github/unnamed-chunk-10-1.png" width="90%" /> \* Make a scatterplot showing the proportion of “Excellent” response values in New York County and Queens County (both in NY State) in each year from 2002 to 2010.

``` r
res_all = filter(hw2_brfss, location_county == "New York County" | location_county == "Queens County") %>% 
       ggplot(aes(x = year, y = excellent)) + 
            geom_point(aes(color = location_county)) +
            labs(
    title = "“Excellent” response proportion in the year 2002 
    in New York County and Queens County",
    x = "year",
    y = "proportion")  
res_all
```

<img src="p8105_hw2_yw3095_files/figure-markdown_github/unnamed-chunk-11-1.png" width="90%" />
